{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LibriSpeech Clean...\n",
      "LibriSpeech Clean WER: 2.55%\n",
      "Processing LibriSpeech Other...\n",
      "LibriSpeech Other WER: 3.39%\n",
      "Processing Common Voice...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 16354it [00:02, 7191.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing an example in Common Voice: 'text'\n",
      "Error processing an example in Common Voice: 'text'\n",
      "Error processing an example in Common Voice: 'text'\n",
      "Error processing an example in Common Voice: 'text'\n",
      "Error processing an example in Common Voice: 'text'\n",
      "No valid examples processed for Common Voice.\n",
      "Processing AMI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hissain/.cache/huggingface/modules/datasets_modules/datasets/ami/2be3c7c8cbb232ed592f22ef14fa122ad3e49dd099a68bff75ed95a82915bb96/ami.py:308: UserWarning: \n",
      "            This version of the AMI dataset is deprecated.\n",
      "            You can download the latest one (based on the official Kaldi recipes) with\n",
      "            >>> load_dataset(\"edinburghcstr/ami\", \"ihm\")  # for the \"independent headset microphone\" part\n",
      "            or\n",
      "            >>> load_dataset(\"edinburghcstr/ami\", \"sdm\")  # for the \"single distant microphone\" part\n",
      "            \n",
      "  warnings.warn(\n",
      "AMI corpus cannot be downloaded using multi-processing. Setting number of downloaded processes `num_proc` to 1. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load AMI: https://groups.inf.ed.ac.uk/ami/AMICorpusMirror//amicorpus/ES2002a/audio/ES2002a.Mix-Headset.wav\n",
      "\n",
      "Evaluation Results:\n",
      "LibriSpeech Clean: 2.55%\n",
      "LibriSpeech Other: 3.39%\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Dependencies\n",
    "#\n",
    "# Install the following packages:\n",
    "# \n",
    "# ```bash\n",
    "# pip install datasets transformers evaluate torchaudio\n",
    "# ```\n",
    "#\n",
    "# This notebook uses:\n",
    "# - datasets (for streaming datasets)\n",
    "# - transformers (for the ASR pipeline)\n",
    "# - evaluate (to compute WER)\n",
    "# - torchaudio (for audio processing if needed)\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import evaluate\n",
    "import datasets\n",
    "\n",
    "# %%\n",
    "# Initialize the ASR pipeline.\n",
    "asr = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"facebook/wav2vec2-base-960h\",\n",
    "    chunk_length_s=30  # adjust chunk length as needed\n",
    ")\n",
    "\n",
    "# Initialize the WER metric.\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "# %%\n",
    "# Define the datasets with configurations.\n",
    "datasets_list = {\n",
    "    \"LibriSpeech Clean\": {\"dataset\": \"librispeech_asr\", \"config\": \"clean\", \"split\": \"test\"},\n",
    "    \"LibriSpeech Other\": {\"dataset\": \"librispeech_asr\", \"config\": \"other\", \"split\": \"test\"},\n",
    "    \"Common Voice\": {\"dataset\": \"mozilla-foundation/common_voice_11_0\", \"config\": \"en\", \"split\": \"test\"},\n",
    "    # Skipping datasets not available on the HF Hub:\n",
    "    # \"VoxPopuli\": {\"dataset\": \"voxpopuli\", \"config\": \"en\", \"split\": \"test\"},\n",
    "    # \"TEDLIUM\": {\"dataset\": \"tedlium\", \"config\": \"release3\", \"split\": \"test\"},\n",
    "    # \"GigaSpeech\": {\"dataset\": \"GigaSpeech\", \"split\": \"test\"},\n",
    "    # \"SPGISpeech\": {\"dataset\": \"spgispeech\", \"split\": \"test\"},\n",
    "    # \"Earnings-22\": {\"dataset\": \"Earnings-22\", \"split\": \"test\"},\n",
    "    \"AMI\": {\"dataset\": \"ami\", \"config\": \"headset-single\", \"split\": \"test\"}\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# %%\n",
    "# Process each dataset in streaming mode (using 5 examples for quick testing).\n",
    "for ds_name, ds_info in datasets_list.items():\n",
    "    print(f\"Processing {ds_name}...\")\n",
    "    try:\n",
    "        ds = datasets.load_dataset(\n",
    "            ds_info[\"dataset\"],\n",
    "            ds_info.get(\"config\", None),\n",
    "            split=ds_info[\"split\"],\n",
    "            streaming=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load {ds_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    ds_small = ds.take(5)\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for example in ds_small:\n",
    "        try:\n",
    "            audio = example[\"audio\"]\n",
    "            # Instead of unpacking sampling_rate, pass the full audio dict\n",
    "            output = asr(audio)\n",
    "            pred = output[\"text\"]\n",
    "            predictions.append(pred)\n",
    "            references.append(example[\"text\"])\n",
    "        except Exception as inner_e:\n",
    "            print(f\"Error processing an example in {ds_name}: {inner_e}\")\n",
    "    \n",
    "    if predictions and references:\n",
    "        wer_score = wer_metric.compute(predictions=predictions, references=references)\n",
    "        results[ds_name] = wer_score\n",
    "        print(f\"{ds_name} WER: {wer_score:.2%}\")\n",
    "    else:\n",
    "        print(f\"No valid examples processed for {ds_name}.\")\n",
    "\n",
    "# %%\n",
    "# Print summary results\n",
    "print(\"\\nEvaluation Results:\")\n",
    "for ds_name, score in results.items():\n",
    "    print(f\"{ds_name}: {score:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
