{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on LibriSpeech Clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'dataset': 'LibriSpeech Clean', 'WER': 100.0, 'total_samples': 3}\n",
      "Evaluating on LibriSpeech Other\n",
      "Result: {'dataset': 'LibriSpeech Other', 'WER': 96.7741935483871, 'total_samples': 3}\n",
      "Evaluating on Common Voice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 16354it [00:02, 8172.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing sample in Common Voice: 'text'\n",
      "Error processing sample in Common Voice: 'text'\n",
      "Error processing sample in Common Voice: 'text'\n",
      "Evaluating on VoxPopuli\n",
      "Error processing sample in VoxPopuli: 'text'\n",
      "Error processing sample in VoxPopuli: 'text'\n",
      "Error processing sample in VoxPopuli: 'text'\n",
      "Evaluating on TEDLIUM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1e2ea1546a452b9c5ba3115934d6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa22391b6bad43999a1b17ea67b05f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ted_talks_iwslt.py:   0%|          | 0.00/14.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading TEDLIUM: BuilderConfig 'release2' not found. Available: ['eu_ca_2014', 'eu_ca_2015', 'eu_ca_2016', 'nl_en_2014', 'nl_en_2015', 'nl_en_2016', 'nl_hi_2014', 'nl_hi_2015', 'nl_hi_2016', 'de_ja_2014', 'de_ja_2015', 'de_ja_2016', 'fr-ca_hi_2014', 'fr-ca_hi_2015', 'fr-ca_hi_2016']\n",
      "Evaluating on GigaSpeech\n",
      "Result: {'dataset': 'GigaSpeech', 'WER': 128.57142857142858, 'total_samples': 3}\n",
      "Evaluating on SPGISpeech\n",
      "Error loading SPGISpeech: Dataset 'speechcolab/spgispeech' doesn't exist on the Hub or cannot be accessed.\n",
      "Evaluating on Earnings-22\n",
      "Error loading Earnings-22: Dataset 'speechcolab/earnings22' doesn't exist on the Hub or cannot be accessed.\n",
      "Evaluating on AMI\n",
      "Error loading AMI: Dataset 'edinburghnlp/ami' doesn't exist on the Hub or cannot be accessed.\n",
      "\n",
      "Full Evaluation Results:\n",
      "             dataset         WER  total_samples\n",
      "0  LibriSpeech Clean  100.000000              3\n",
      "1  LibriSpeech Other   96.774194              3\n",
      "2         GigaSpeech  128.571429              3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "def load_and_evaluate_dataset(dataset_name, model, processor, max_samples=3):\n",
    "    \"\"\"\n",
    "    Load a dataset with streaming, preprocess it, and evaluate speech recognition performance\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset\n",
    "        model: Pretrained Whisper model\n",
    "        processor: Whisper processor for preparing audio inputs\n",
    "        max_samples (int): Maximum number of samples to evaluate\n",
    "    \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    # Dataset loading configurations with streaming\n",
    "    dataset_configs = {\n",
    "        'LibriSpeech Clean': {\n",
    "            'path': 'librispeech_asr', \n",
    "            'name': 'clean', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'LibriSpeech Other': {\n",
    "            'path': 'librispeech_asr', \n",
    "            'name': 'other', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'Common Voice': {\n",
    "            'path': 'mozilla-foundation/common_voice_11_0', \n",
    "            'name': 'en', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'VoxPopuli': {\n",
    "            'path': 'facebook/voxpopuli', \n",
    "            'name': 'en', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'TEDLIUM': {\n",
    "            'path': 'ted_talks_iwslt', \n",
    "            'name': 'release2', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'GigaSpeech': {\n",
    "            'path': 'speechcolab/gigaspeech', \n",
    "            'name': 'xs', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'SPGISpeech': {\n",
    "            'path': 'speechcolab/spgispeech', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'Earnings-22': {\n",
    "            'path': 'speechcolab/earnings22', \n",
    "            'split': 'test'\n",
    "        },\n",
    "        'AMI': {\n",
    "            'path': 'edinburghnlp/ami', \n",
    "            'split': 'test'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Prepare device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # Prepare metric\n",
    "    wer_metric = evaluate.load(\"wer\")\n",
    "    \n",
    "    # Collect predictions and references\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    # Streaming dataset load\n",
    "    try:\n",
    "        # Get configuration for the dataset\n",
    "        config = dataset_configs.get(dataset_name, {})\n",
    "        \n",
    "        # Load dataset with streaming\n",
    "        dataset = load_dataset(\n",
    "            config.get('path', dataset_name.lower().replace(' ', '_')), \n",
    "            name=config.get('name'),\n",
    "            split=config.get('split', 'test'),\n",
    "            streaming=True  # Key change: Enable streaming\n",
    "        )\n",
    "        \n",
    "        # Limit samples using iterator\n",
    "        for idx, item in enumerate(dataset):\n",
    "            if idx >= max_samples:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                # Prepare audio input\n",
    "                audio = item['audio']\n",
    "                ref_text = item['text']\n",
    "                \n",
    "                # Process audio\n",
    "                input_features = processor(\n",
    "                    audio['array'], \n",
    "                    sampling_rate=audio['sampling_rate'], \n",
    "                    return_tensors=\"pt\"\n",
    "                ).input_features.to(device)\n",
    "                \n",
    "                # Generate transcription\n",
    "                with torch.no_grad():\n",
    "                    predicted_ids = model.generate(input_features)\n",
    "                    pred_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "                \n",
    "                predictions.append(pred_text)\n",
    "                references.append(ref_text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample in {dataset_name}: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate Word Error Rate\n",
    "    if predictions and references:\n",
    "        wer = wer_metric.compute(predictions=predictions, references=references)\n",
    "        return {\n",
    "            'dataset': dataset_name,\n",
    "            'WER': wer * 100,  # Convert to percentage\n",
    "            'total_samples': len(predictions)\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "def evaluate_model_across_datasets(model_name=\"openai/whisper-small\", samples_per_dataset=3):\n",
    "    \"\"\"\n",
    "    Evaluate a Whisper speech recognition model across multiple datasets\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Hugging Face Whisper model identifier\n",
    "        samples_per_dataset (int): Number of samples to test per dataset\n",
    "    \n",
    "    Returns:\n",
    "        list: Evaluation results for each dataset\n",
    "    \"\"\"\n",
    "    # Load model and processor\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    \n",
    "    # Datasets to evaluate\n",
    "    datasets = [\n",
    "        'LibriSpeech Clean', \n",
    "        'LibriSpeech Other', \n",
    "        'Common Voice', \n",
    "        'VoxPopuli', \n",
    "        'TEDLIUM', \n",
    "        'GigaSpeech', \n",
    "        'SPGISpeech', \n",
    "        'Earnings-22', \n",
    "        'AMI'\n",
    "    ]\n",
    "    \n",
    "    # Evaluate on each dataset\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        print(f\"Evaluating on {dataset}\")\n",
    "        result = load_and_evaluate_dataset(\n",
    "            dataset_name=dataset, \n",
    "            model=model, \n",
    "            processor=processor, \n",
    "            max_samples=samples_per_dataset\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"Result: {result}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Evaluate the model\n",
    "    evaluation_results = evaluate_model_across_datasets(samples_per_dataset=3)\n",
    "    \n",
    "    # Optional: Display results in a pandas DataFrame\n",
    "    import pandas as pd\n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    print(\"\\nFull Evaluation Results:\")\n",
    "    print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
